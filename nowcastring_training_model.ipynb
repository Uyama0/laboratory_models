{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradyumnaGupta/rainnet/blob/master/RainNet_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUvMCjpZPRUl",
        "outputId": "43ee0e59-895f-47ad-bf33-4feac59bc3b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVfiBtxzdlF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3656d8-0046-4654-e5ac-76c39228bfc5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import ImageFile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score\n",
        "import math\n",
        "import time\n",
        "import albumentations\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcUSl1wfdeOt"
      },
      "source": [
        "def Scaler(array):\n",
        "    \"\"\"\n",
        "    Функция для логарифмического масштабирования массива.\n",
        "    \"\"\"\n",
        "    return np.log(array + 0.01)\n",
        "\n",
        "\n",
        "def invScaler(array):\n",
        "    \"\"\"\n",
        "    Функция для обратного преобразования массива после логарифмического масштабирования.\n",
        "    \"\"\"\n",
        "    return np.exp(array) - 0.01\n",
        "\n",
        "\n",
        "def pad_to_shape(array, from_shape=900, to_shape=928, how=\"mirror\"):\n",
        "    \"\"\"\n",
        "    Функция для дополнения массива до указанной формы с использованием различных методов заполнения (например, \"mirror\" или \"zero\").\n",
        "    \"\"\"\n",
        "    # Рассчитываем, сколько нужно добавить паддинга относительно исходного разрешения\n",
        "    padding = int((to_shape - from_shape) / 2)\n",
        "    # Для формы входных данных (batch, W, H, channels)\n",
        "    if how == \"zero\":\n",
        "        array_padded = np.pad(array, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode=\"constant\", constant_values=0)\n",
        "    elif how == \"mirror\":\n",
        "        array_padded = np.pad(array, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode=\"reflect\")\n",
        "    return array_padded\n",
        "\n",
        "\n",
        "def pred_to_rad(pred, from_shape=928, to_shape=900):\n",
        "    \"\"\"\n",
        "    Функция для обрезки предсказаний модели до указанной формы.\n",
        "    \"\"\"\n",
        "    # Форма предсказаний 12, 928, 928\n",
        "    padding = int((from_shape - to_shape) / 2)\n",
        "    return pred[::, padding:padding+to_shape, padding:padding+to_shape].copy()\n",
        "\n",
        "\n",
        "def data_preprocessing(X):\n",
        "    \"\"\"\n",
        "    Предобработка данных:\n",
        "    0. Подгонка формы для пакета данных.\n",
        "    1. Логарифмическое масштабирование.\n",
        "    2. Дополнение до формы 928x928.\n",
        "    \"\"\"\n",
        "    X = np.moveaxis(X, 0, -1)\n",
        "    X = X[np.newaxis, ::, ::, ::]\n",
        "    X = Scaler(X)\n",
        "    X = pad_to_shape(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "def data_postprocessing(nwcst):\n",
        "    \"\"\"\n",
        "    Постобработка данных:\n",
        "    0. Удаление пустых размерностей.\n",
        "    1. Обратное преобразование от логарифмического масштабирования.\n",
        "    2. Преобразование обратно от 928x928 к 900x900.\n",
        "    3. Возвращение только положительных значений.\n",
        "    \"\"\"\n",
        "    nwcst = np.squeeze(np.array(nwcst))\n",
        "    nwcst = invScaler(nwcst)\n",
        "    nwcst = pred_to_rad(nwcst)\n",
        "    nwcst = np.where(nwcst > 0, nwcst, 0)\n",
        "    return nwcst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3slT2sUndeMp"
      },
      "source": [
        "class Dataset(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataset_dict,\n",
        "            image_names,\n",
        "            batch_size\n",
        "    ):\n",
        "        self.keys = image_names\n",
        "        self.dataset = dataset_dict\n",
        "        self.bs = batch_size\n",
        "\n",
        "    def get_index(self,i):\n",
        "      x = []\n",
        "      for j in range(4):\n",
        "        try:\n",
        "          arr = np.array(self.dataset.get(self.keys[i+j]))\n",
        "        except:\n",
        "          print(i,j)\n",
        "        x.append(arr)\n",
        "\n",
        "      x = data_preprocessing(np.stack(x,0))\n",
        "      x = np.squeeze(x)\n",
        "      y = np.squeeze(data_preprocessing(np.array(self.dataset[self.keys[i+3]])[np.newaxis,:,:]))\n",
        "\n",
        "      return x.astype('float32'),y.astype('float32')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      X = []\n",
        "      Y = []\n",
        "\n",
        "      for i in range(index*self.bs,(index+1)*self.bs):\n",
        "        x,y = self.get_index(i)\n",
        "        X.append(x[np.newaxis,:])\n",
        "        Y.append(y[np.newaxis,:])\n",
        "\n",
        "      return X,Y\n",
        "\n",
        "    def __len__(self):\n",
        "      return (len(self.keys) - 4)//self.bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBMTBcp5deHx"
      },
      "source": [
        "import h5py\n",
        "dataset_dict = h5py.File('drive/MyDrive/RYDL.hdf5', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvLHuAAVqEk"
      },
      "source": [
        "\n",
        "\n",
        "Вытаскиваем ключи и разбиваем данные на train и validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEmMAg5xdeFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd7f88f-b13f-4557-8d2e-a9c66a0cd559"
      },
      "source": [
        "import ast\n",
        "with open('drive/MyDrive/RYDL_keys.txt','r') as f:\n",
        "  image_names = ast.literal_eval(f.read())\n",
        "image_names = [name for name in image_names if name[:4]>'2012']\n",
        "\n",
        "train_images = [name for name in tqdm(image_names) if \"2017\" not in name]\n",
        "val_images = [name for name in tqdm(image_names) if name[0:4]==\"2017\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 221211/221211 [00:00<00:00, 2273532.11it/s]\n",
            "100%|██████████| 221211/221211 [00:00<00:00, 1789822.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvIs5J1Mknig"
      },
      "source": [
        "train_dataset = Dataset(\n",
        "    dataset_dict=dataset_dict,\n",
        "    image_names=train_images,\n",
        "    batch_size=1\n",
        ")\n",
        "\n",
        "valid_dataset = Dataset(\n",
        "    dataset_dict=dataset_dict,\n",
        "    image_names=val_images,\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA8ePVeaknfq"
      },
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "def rainnet(input_shape=(928, 928, 4), mode=\"regression\"):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    conv1f = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1f = Activation(\"relu\")(conv1f)\n",
        "    conv1s = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv1f)\n",
        "    conv1s = Activation(\"relu\")(conv1s)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1s)\n",
        "\n",
        "    conv2f = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2f = Activation(\"relu\")(conv2f)\n",
        "    conv2s = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv2f)\n",
        "    conv2s = Activation(\"relu\")(conv2s)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2s)\n",
        "\n",
        "    conv3f = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3f = Activation(\"relu\")(conv3f)\n",
        "    conv3s = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv3f)\n",
        "    conv3s = Activation(\"relu\")(conv3s)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3s)\n",
        "\n",
        "    conv4f = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4f = Activation(\"relu\")(conv4f)\n",
        "    conv4s = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv4f)\n",
        "    conv4s = Activation(\"relu\")(conv4s)\n",
        "    drop4 = Dropout(0.5)(conv4s)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5f = Conv2D(1024, 3, padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5f = Activation(\"relu\")(conv5f)\n",
        "    conv5s = Conv2D(1024, 3, padding='same', kernel_initializer='he_normal')(conv5f)\n",
        "    conv5s = Activation(\"relu\")(conv5s)\n",
        "    drop5 = Dropout(0.5)(conv5s)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(drop5), conv4s], axis=3)\n",
        "    conv6 = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(up6)\n",
        "    conv6 = Activation(\"relu\")(conv6)\n",
        "    conv6 = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    conv6 = Activation(\"relu\")(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3s], axis=3)\n",
        "    conv7 = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(up7)\n",
        "    conv7 = Activation(\"relu\")(conv7)\n",
        "    conv7 = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv7)\n",
        "    conv7 = Activation(\"relu\")(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2s], axis=3)\n",
        "    conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(up8)\n",
        "    conv8 = Activation(\"relu\")(conv8)\n",
        "    conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    conv8 = Activation(\"relu\")(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1s], axis=3)\n",
        "    conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(up9)\n",
        "    conv9 = Activation(\"relu\")(conv9)\n",
        "    conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Activation(\"relu\")(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "\n",
        "    # Выходной слои\n",
        "\n",
        "    if mode == \"regression\":\n",
        "        outputs = Conv2D(1, 1, activation='linear')(conv9)\n",
        "    elif mode == \"segmentation\":\n",
        "        outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgdwXYGbx1i"
      },
      "source": [
        "model = rainnet()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4),loss='log_cosh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Xe3fDrwRYs"
      },
      "source": [
        "model.fit(x=train_dataset,validation_data=valid_dataset,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}